<html>
<h2 id="practical-machine-learning-project-writeup">Practical Machine Learning Project Writeup</h2>

<p><em>Krzysztof Koremba 20 Aug 2015</em></p>



<h3 id="background">Background</h3>

<p>The goal of the model was to predict how people did their excersises using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants of the test.</p>



<h3 id="data">Data</h3>

<p>First step of the project was to download the training data. It was acquired from the web:  </p>

<blockquote>
  <p><code>download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",</code> <br>
  <code>destfile = "pml_training.csv")</code></p>
</blockquote>

<p>The second file contained 20 examples of unlabeled data</p>

<blockquote>
  <p><code>download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",</code>  <br>
  <code>destfile = "pml_test.csv")</code></p>
</blockquote>

<p>After downloading and reading the file, a quick examination of the data was made:  </p>

<blockquote>
  <p><code>trainSet &lt;- read.csv("pml_training.csv")</code></p>
  
  <p><code>testSet &lt;- read.csv("pml_test.csv")</code></p>
  
  <p><code>str(trainSet)</code></p>
  
  <p><code>summary(trainSet)</code></p>
  
  <p><code>head(trainSet)</code></p>
</blockquote>

<p>We can see that:</p>

<ul>
<li>there are 19622 obs. of  160 variables in the dataset</li>
<li>there are many variables with missing data</li>
<li>there are token variables  <br>
<code>(i.e. skewness_yaw_dumbbell   : Factor w/ 2 levels "","#DIV/0!": 1 1 1 1 1 1 1 1 1 ...)</code></li>
<li>there are variables with many empty string “” values</li>
</ul>

<p>My initial goal was to remove variables with more than 50% of missing data, but since there were only two leveles of NA’s (0 and 98%) - then it was leaving only the completely filled variables:</p>

<blockquote>
  <p><code>na_vect &lt;- sapply(trainSet, function(x) ifelse(is.na(x)|x %in% c("","#DIV/0!") ,1,0))</code></p>
  
  <p><code>na_vect&lt;- as.data.frame(na_vect)</code></p>
  
  <p><code>na_stat &lt;- sapply(na_vect, mean)</code></p>
  
  <p><code>no_nas &lt;- na_stat == 0</code></p>
  
  <p><code>trainSet &lt;- trainSet[,no_nas]</code></p>
</blockquote>

<p>I have also removed timestamps, username, X (row number) and a “window” variables</p>

<blockquote>
  <p><code>$ X                   : int  1 2 3 4 5 6 7 8 9 10 ...</code></p>
  
  <p><code>$ user_name           : Factor w/ 6 levels "adelmo","carlitos",..: 2 2 2 2 2 2 2 2 2 2 ...</code></p>
  
  <p><code>$ raw_timestamp_part_1: int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...</code></p>
  
  <p><code>$ raw_timestamp_part_2: int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...</code></p>
  
  <p><code>$ cvtd_timestamp      : Factor w/ 20 levels "02/12/2011 13:32",..: 9 9 9 9 9 9 9 9 9 9 ...</code></p>
  
  <p><code>$ new_window          : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...</code></p>
  
  <p><code>$ num_window          : int  11 11 11 12 12 12 12 12 12 12 ...</code></p>
</blockquote>

<p>As a result my final data set had 53 variables: 52 numeric predictors and a factor output (classe variable).</p>



<h3 id="fiting-model">Fiting model</h3>

<p>For modeling I used caret package:</p>

<blockquote>
  <p><code>library(caret)</code></p>
</blockquote>

<p>First I made a split for training / test sample. I used 80% for training and 20% for testing:</p>

<blockquote>
  <p><code>inTrain &lt;- createDataPartition(trainSet$classe, p=.8, list = F)</code></p>
  
  <p><code>Tr &lt;- trainSet[inTrain,]</code></p>
  
  <p><code>Tst &lt;- trainSet[-inTrain,]</code></p>
</blockquote>

<p>The best results were produced with a random forrest algorithm, though it took a while a do all processing:</p>

<blockquote>
  <p><code>grid &lt;- expand.grid(ntree = seq(100, 1000, by = 100), shrinkage = 0.1, mtry =20)</code></p>
  
  <p><code>cvCtrl &lt;- trainControl(method = "repeatedcv", repeats = 5, number = 10)</code></p>
  
  <p><code>model_rf &lt;- train(classe~., data = Tr, method = "rf",</code> <br>
   <code>expand.grid = grid, trControl = cvCtrl )</code></p>
</blockquote>

<p>Variable importance for final model:</p>

<p><img src="Rplot01.png" alt="Variable importance for final model" title=""></p>



<h3 id="results">Results</h3>

<p><strong>Resulst on Tr set:</strong></p>

<blockquote>
  <p><code>confusionMatrix(predict(model_rf, Tr), Tr$classe)</code></p>
</blockquote>

<p>Confusion Matrix and Statistics</p>

<pre><code>      Reference
Prediction    A    B    C    D    E
         A 4464    0    0    0    0
        B    0 3038    0    0    0
        C    0    0 2738    0    0
        D    0    0    0 2573    0
        E    0    0    0    0 2886
</code></pre>

<p>Overall Statistics</p>

<pre><code>           Accuracy : 1          
             95% CI : (0.9998, 1)
No Information Rate : 0.2843     
P-Value [Acc &gt; NIR] : &lt; 2.2e-16  

              Kappa : 1          
</code></pre>

<p>Mcnemar’s Test P-Value : NA         </p>

<p>Statistics by Class:</p>

<pre><code>                       Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
</code></pre>

<p><strong>Results on Tst set (out of sample error estimation)</strong></p>

<p>Confusion Matrix and Statistics</p>

<pre><code>      Reference
Prediction    A    B    C    D    E
         A 1114    4    0    0    0
        B    2  755    9    0    0
        C    0    0  675   10    0
        D    0    0    0  633    1
        E    0    0    0    0  720
</code></pre>

<p>Overall Statistics</p>

<pre><code>           Accuracy : 0.9934          
             95% CI : (0.9903, 0.9957)
No Information Rate : 0.2845          
P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

              Kappa : 0.9916          
</code></pre>

<p>Mcnemar’s Test P-Value : NA              </p>

<p>Statistics by Class:</p>

<pre><code>                 Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9982   0.9947   0.9868   0.9844   0.9986
Specificity            0.9986   0.9965   0.9969   0.9997   1.0000
Pos Pred Value         0.9964   0.9856   0.9854   0.9984   1.0000
Neg Pred Value         0.9993   0.9987   0.9972   0.9970   0.9997
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2840   0.1925   0.1721   0.1614   0.1835
Detection Prevalence   0.2850   0.1953   0.1746   0.1616   0.1835
Balanced Accuracy      0.9984   0.9956   0.9919   0.9921   0.9993
</code></pre>



<h3 id="prediction-on-pml-testingcsv">Prediction on <em>pml-testing.csv</em></h3>

<p>Model gives following predictions on <em>pml-testing</em> data (it scores maximum 20 points):</p>

<blockquote>
  <p>[1] B A B A A E D B A A B C B A E E A B B B</p>
</blockquote>
</html>
